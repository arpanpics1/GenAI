1. What is the context- window 
2. Why tokenization is important in LLM 
3. Temperature 
4. Attention mechanism 
5. Guardrails for Hallucinations
6. What are the advantages of BM25 over other ranking algorithms?”
  Refined: “Compare BM25 to TF-IDF and a neural ranking model like BERT in terms of strengths, weaknesses, and use cases.”
  Why Better: Encourages critical thinking by comparing BM25 to other approaches, highlighting its simplicity, efficiency, and limitations (e.g., lack of semantic understanding vs. neural models).
7. a
8. a
9. a
10. a
11. a
12. a
13. a
14. a
15. a
16. a
17. a
18. a
19. a
